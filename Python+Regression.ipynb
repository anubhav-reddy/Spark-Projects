{"nbformat_minor": 1, "cells": [{"source": "## Creating a Regression Model\n\nIn this exercise, you will implement a regression model that uses features of a flight to predict how late or early it will arrive.\n\n### Import Spark SQL and Spark ML Libraries\n\nFirst, import the libraries you will need:", "cell_type": "markdown", "metadata": {}}, {"execution_count": 33, "cell_type": "code", "source": "from pyspark.sql.types import *\nfrom pyspark.sql.functions import *\n\nfrom pyspark.ml.regression import LinearRegression\nfrom pyspark.ml.feature import VectorAssembler", "outputs": [], "metadata": {"scrolled": false, "collapsed": false}}, {"source": "### Load Source Data\nThe data for this exercise is provided as a CSV file containing details of flights. The data includes specific characteristics (or *features*) for each flight, as well as a *label* column indicating how many minutes late or early the flight arrived.\n\nYou will load this data into a DataFrame and display it.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 7, "cell_type": "code", "source": "csv = spark.read.csv('wasb:///data/flights.csv', inferSchema=True, header=True)\ncsv.show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+----------+---------+-------+---------------+-------------+--------+--------+\n|DayofMonth|DayOfWeek|Carrier|OriginAirportID|DestAirportID|DepDelay|ArrDelay|\n+----------+---------+-------+---------------+-------------+--------+--------+\n|        19|        5|     DL|          11433|        13303|      -3|       1|\n|        19|        5|     DL|          14869|        12478|       0|      -8|\n|        19|        5|     DL|          14057|        14869|      -4|     -15|\n|        19|        5|     DL|          15016|        11433|      28|      24|\n|        19|        5|     DL|          11193|        12892|      -6|     -11|\n|        19|        5|     DL|          10397|        15016|      -1|     -19|\n|        19|        5|     DL|          15016|        10397|       0|      -1|\n|        19|        5|     DL|          10397|        14869|      15|      24|\n|        19|        5|     DL|          10397|        10423|      33|      34|\n|        19|        5|     DL|          11278|        10397|     323|     322|\n|        19|        5|     DL|          14107|        13487|      -7|     -13|\n|        19|        5|     DL|          11433|        11298|      22|      41|\n|        19|        5|     DL|          11298|        11433|      40|      20|\n|        19|        5|     DL|          11433|        12892|      -2|      -7|\n|        19|        5|     DL|          10397|        12451|      71|      75|\n|        19|        5|     DL|          12451|        10397|      75|      57|\n|        19|        5|     DL|          12953|        10397|      -1|      10|\n|        19|        5|     DL|          11433|        12953|      -3|     -10|\n|        19|        5|     DL|          10397|        14771|      31|      38|\n|        19|        5|     DL|          13204|        10397|       8|      25|\n+----------+---------+-------+---------------+-------------+--------+--------+\nonly showing top 20 rows"}], "metadata": {"scrolled": false, "collapsed": false}}, {"source": "### Prepare the Data\nMost modeling begins with exhaustive exploration and preparation of the data. In this example, you will simply select a subset of columns to use as *features* as well as the **ArrDelay** column, which will be the *label* your model will predict.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 8, "cell_type": "code", "source": "data = csv.select(\"DayofMonth\", \"DayOfWeek\", \"OriginAirportID\", \"DestAirportID\", \"DepDelay\", \"ArrDelay\")\ndata.show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+----------+---------+---------------+-------------+--------+--------+\n|DayofMonth|DayOfWeek|OriginAirportID|DestAirportID|DepDelay|ArrDelay|\n+----------+---------+---------------+-------------+--------+--------+\n|        19|        5|          11433|        13303|      -3|       1|\n|        19|        5|          14869|        12478|       0|      -8|\n|        19|        5|          14057|        14869|      -4|     -15|\n|        19|        5|          15016|        11433|      28|      24|\n|        19|        5|          11193|        12892|      -6|     -11|\n|        19|        5|          10397|        15016|      -1|     -19|\n|        19|        5|          15016|        10397|       0|      -1|\n|        19|        5|          10397|        14869|      15|      24|\n|        19|        5|          10397|        10423|      33|      34|\n|        19|        5|          11278|        10397|     323|     322|\n|        19|        5|          14107|        13487|      -7|     -13|\n|        19|        5|          11433|        11298|      22|      41|\n|        19|        5|          11298|        11433|      40|      20|\n|        19|        5|          11433|        12892|      -2|      -7|\n|        19|        5|          10397|        12451|      71|      75|\n|        19|        5|          12451|        10397|      75|      57|\n|        19|        5|          12953|        10397|      -1|      10|\n|        19|        5|          11433|        12953|      -3|     -10|\n|        19|        5|          10397|        14771|      31|      38|\n|        19|        5|          13204|        10397|       8|      25|\n+----------+---------+---------------+-------------+--------+--------+\nonly showing top 20 rows"}], "metadata": {"collapsed": false}}, {"source": "### Split the Data\nIt is common practice when building supervised machine learning models to split the source data, using some of it to train the model and reserving some to test the trained model. In this exercise, you will use 70% of the data for training, and reserve 30% for testing.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 31, "cell_type": "code", "source": "splits = data.randomSplit([0.4, 0.3],seed = 123)\ntrain = splits[0]\ntest = splits[1]\ntrain_rows = train.count()\ntest_rows = test.count()\nprint \"Training Rows:\", train_rows, \" Testing Rows:\", test_rows", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Training Rows: 1544156  Testing Rows: 1158062"}], "metadata": {"collapsed": false}}, {"source": "### Prepare the Training Data\nTo train the regression model, you need a training data set that includes a vector of numeric features, and a label column. In this exercise, you will use the **VectorAssembler** class to transform the feature columns into a vector, and then rename the **ArrDelay** column to **label**.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 32, "cell_type": "code", "source": "assembler = VectorAssembler(inputCols = [\"DayofMonth\", \"DayOfWeek\", \"OriginAirportID\", \"DestAirportID\", \"DepDelay\"], outputCol=\"features\")\ntraining = assembler.transform(train).select(col(\"features\"), (col(\"ArrDelay\").cast(\"Int\").alias(\"label\")))\ntraining.show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+--------------------+-----+\n|            features|label|\n+--------------------+-----+\n|[1.0,1.0,10140.0,...|  -11|\n|[1.0,1.0,10140.0,...|   -9|\n|[1.0,1.0,10140.0,...|    4|\n|[1.0,1.0,10140.0,...|   -9|\n|[1.0,1.0,10140.0,...|  -14|\n|[1.0,1.0,10140.0,...|  -14|\n|[1.0,1.0,10140.0,...|  -12|\n|[1.0,1.0,10140.0,...|   -6|\n|[1.0,1.0,10140.0,...|  -11|\n|[1.0,1.0,10140.0,...|   19|\n|[1.0,1.0,10140.0,...|   23|\n|[1.0,1.0,10140.0,...|   41|\n|[1.0,1.0,10140.0,...|   -6|\n|[1.0,1.0,10140.0,...|   -5|\n|[1.0,1.0,10140.0,...|   -6|\n|[1.0,1.0,10140.0,...|   -1|\n|[1.0,1.0,10140.0,...|    6|\n|[1.0,1.0,10140.0,...|   13|\n|[1.0,1.0,10140.0,...|   38|\n|[1.0,1.0,10140.0,...|   38|\n+--------------------+-----+\nonly showing top 20 rows"}], "metadata": {"scrolled": false, "collapsed": false}}, {"execution_count": 29, "cell_type": "code", "source": "", "outputs": [{"output_type": "stream", "name": "stdout", "text": "VectorAssembler_4f749ad0b3491277f590"}], "metadata": {"collapsed": false}}, {"source": "### Train a Regression Model\nNext, you need to train a regression model using the training data. To do this, create an instance of the regression algorithm you want to use and use its **fit** method to train a model based on the training DataFrame. In this exercise, you will use a *Linear Regression* algorithm - though you can use the same technique for any of the regression algorithms supported in the spark.ml API.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 13, "cell_type": "code", "source": "lr = LinearRegression(labelCol=\"label\",featuresCol=\"features\", maxIter=10, regParam=0.3)\nmodel = lr.fit(training)\nprint \"Model trained!\"", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Model trained!"}], "metadata": {"scrolled": false, "collapsed": false}}, {"execution_count": 26, "cell_type": "code", "source": "# Print the coefficients and intercept for linear regression\n\nprint(\"Coefficients: %s\" % str(model.coefficients))\nprint(\"Intercept: %s\" % str(model.intercept))", "outputs": [{"output_type": "stream", "name": "stdout", "text": "Coefficients: [0.0103789535947,-0.137214365452,0.000194773062303,-0.000230150067944,0.997082358651]\nIntercept: -3.01287131258"}], "metadata": {"collapsed": false}}, {"source": "### Prepare the Testing Data\nNow that you have a trained model, you can test it using the testing data you reserved previously. First, you need to prepare the testing data in the same way as you did the training data by transforming the feature columns into a vector. This time you'll rename the **ArrDelay** column to **trueLabel**.", "cell_type": "markdown", "metadata": {}}, {"execution_count": 14, "cell_type": "code", "source": "testing = assembler.transform(test).select(col(\"features\"), (col(\"ArrDelay\")).cast(\"Int\").alias(\"trueLabel\"))\ntesting.show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+--------------------+---------+\n|            features|trueLabel|\n+--------------------+---------+\n|[1.0,1.0,10140.0,...|      -18|\n|[1.0,1.0,10140.0,...|      -17|\n|[1.0,1.0,10140.0,...|      -12|\n|[1.0,1.0,10140.0,...|       94|\n|[1.0,1.0,10140.0,...|      -23|\n|[1.0,1.0,10140.0,...|      -11|\n|[1.0,1.0,10140.0,...|      -12|\n|[1.0,1.0,10140.0,...|      -10|\n|[1.0,1.0,10140.0,...|        5|\n|[1.0,1.0,10140.0,...|       14|\n|[1.0,1.0,10140.0,...|       -8|\n|[1.0,1.0,10140.0,...|       -9|\n|[1.0,1.0,10140.0,...|       -5|\n|[1.0,1.0,10140.0,...|        2|\n|[1.0,1.0,10140.0,...|       19|\n|[1.0,1.0,10140.0,...|      -19|\n|[1.0,1.0,10140.0,...|      -12|\n|[1.0,1.0,10140.0,...|      -25|\n|[1.0,1.0,10140.0,...|       -1|\n|[1.0,1.0,10140.0,...|       -2|\n+--------------------+---------+\nonly showing top 20 rows"}], "metadata": {"collapsed": false}}, {"source": "### Test the Model\nNow you're ready to use the **transform** method of the model to generate some predictions. You can use this approach to predict arrival delay for flights where the label is unknown; but in this case you are using the test data which includes a known true label value, so you can compare the predicted number of minutes late or early to the actual arrival delay. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": 30, "cell_type": "code", "source": "prediction = model.transform(testing)\npredicted = prediction.select(\"features\", \"prediction\", \"trueLabel\")\npredicted.show()", "outputs": [{"output_type": "stream", "name": "stdout", "text": "+--------------------+-------------------+---------+\n|            features|         prediction|trueLabel|\n+--------------------+-------------------+---------+\n|[1.0,1.0,10140.0,...| -5.551742846403851|      -18|\n|[1.0,1.0,10140.0,...| -5.551742846403851|      -17|\n|[1.0,1.0,10140.0,...|-3.5575781291020716|      -12|\n|[1.0,1.0,10140.0,...|   73.1201798582081|       94|\n|[1.0,1.0,10140.0,...| -8.741379280924354|      -23|\n|[1.0,1.0,10140.0,...| -6.747214563622576|      -11|\n|[1.0,1.0,10140.0,...| -3.755967487669907|      -12|\n|[1.0,1.0,10140.0,...| -3.755967487669907|      -10|\n|[1.0,1.0,10140.0,...|  8.209020816140768|        5|\n|[1.0,1.0,10140.0,...| 20.174009119951442|       14|\n|[1.0,1.0,10140.0,...| -7.751891874515621|       -8|\n|[1.0,1.0,10140.0,...| -5.757727157213843|       -9|\n|[1.0,1.0,10140.0,...|-3.7635624399120635|       -5|\n|[1.0,1.0,10140.0,...|-0.7723153639593945|        2|\n|[1.0,1.0,10140.0,...| 18.172249450407502|       19|\n|[1.0,1.0,10140.0,...|-13.735766926828623|      -19|\n|[1.0,1.0,10140.0,...|-12.738684568177733|      -12|\n|[1.0,1.0,10140.0,...| -9.747437492225066|      -25|\n|[1.0,1.0,10140.0,...|-7.7532727749232855|       -1|\n|[1.0,1.0,10140.0,...| -5.759108057621507|       -2|\n+--------------------+-------------------+---------+\nonly showing top 20 rows"}], "metadata": {"scrolled": false, "collapsed": false}}, {"source": "Looking at the result, the **prediction** column contains the predicted value for the label, and the **trueLabel** column contains the actual known value from the testing data. It looks like there is some variance between the predictions and the actual values (the individual differences are referred to as *residuals*)- later in this course you'll learn how to measure the accuracy of a model.", "cell_type": "markdown", "metadata": {}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "PySpark", "name": "pysparkkernel", "language": ""}, "language_info": {"mimetype": "text/x-python", "pygments_lexer": "python2", "name": "pyspark", "codemirror_mode": {"version": 2, "name": "python"}}}}